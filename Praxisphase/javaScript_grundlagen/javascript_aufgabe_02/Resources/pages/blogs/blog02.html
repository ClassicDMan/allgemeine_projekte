<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Juan HyBlogs - Zwischen Wahrheit und Täuschung</title>
    <link rel="stylesheet" href="../../css/beitraege.css">
    <link rel="stylesheet" href="../../css/global.css">
    <link rel="icon" type="image/png" href="../../../assets/Logo/J.png">
</head>

<body>

    <header>
        <div class="logo-div">
            <a href="../../home.html"><img src="../../../assets/Logo/J.png" alt="Logo of the Site" id="logo"></a>
            <h1>Juan HyBlogs</h1>
        </div>
    </header>
    <main>
        <article class="blog-post">
            <h2>Zwischen Wahrheit und Täuschung: Wie Technologie im Kampf gegen Desinformation hilft</h2>
            <p><strong>Autor:</strong> Juan</p>
            <p><strong>E-Mail:</strong> autor@example.com</p>
            <p>
                Soziale Netzwerke fördern den schnellen Informationsaustausch, begünstigen aber auch die Verbreitung von
                Des- und Fehlinformationen – mit gravierenden Folgen.
                Technische Ansätze wie die Verwendung von Indikatoren können helfen, Grauzonen im Wahrheitsgehalt zu
                entschlüsseln und die richtige Einschätzung von Informationen zu erleichtern:
                eine entscheidende Grundlage für eine widerstandsfähige Demokratie und Gesellschaft.
    
                Grauzonen des Wahrheitsgehalts: Wie Technologie im Umgang mit Desinformation unterstützen kann. Soziale
                Netzwerke sind für in der Politik Aktive zu einem unverzichtbaren Werkzeug
                für die Kommunikation mit der Gesellschaft geworden. Durch hohe Geschwindigkeit und (vermeintliche)
                Anonymität begünstigen soziale Netzwerke aber auch die Verbreitung
                von absichtlich irreführenden Desinformationen und unabsichtlich irreführenden Fehlinformationen. Die
                Folgen: Manipulierte Wahlen, Polarisierungen etwa
                in Gesundheitsfragen und damit einhergehend auch gesundheitliche Folgen für Einzelne. Im Kontext der
                U.S.-Wahl im Jahre 2020 zeigten sich die Konsequenzen gezielter
                Fehlinformationen in Form des Sturms auf das Kapitol. Auch die jüngsten U.S.-Wahlen waren im Vorfeld durch
                die Erwartung gezielter Desinformation aus dem In- und Ausland geprägt.
    
                Wie kann Desinformation und Fehlinformation technisch adressiert werden? Fehl- und Desinformationen sind
                oftmals durch Graubereiche geprägt. So enthalten sie in der Regel nicht nur falsche Informationen, sondern
                setzen z.B. wahre Informationen in den falschen Kontext. Dies ist beispielsweise in Form von Bildmaterial zu
                Militärparaden zu beobachten, welches mit aktuellen Kriegen in den falschen Zusammenhang gebracht wird.
    
                Neben Maßnahmen wie der Stärkung von Medienkompetenz stellen technische Ansätze eine ergänzende Intervention
                gegen den Einfluss solcher Manipulationen dar. So bestehen Bestrebungen, die problematischen Inhalte
                automatisiert zu detektieren. Doch was ist „problematisch“? Die Forschung steht vor folgenden
                Herausforderungen: Multimodalität (d. h. eine komplexe Kombination von Text, Audio und Video), Mischungen
                aus wahren und falschen Informationen, der Verantwortlichkeit für die Datensätze zum Trainieren der
                Programme zur automatischen Erkennung, der Detektion, von manipulativen Inhalten.
    
                Neben der Detektion bestehen technikgestützte Bestrebungen zu darauffolgenden Entscheidungen, was mit
                erfolgreich detektierten Inhalten geschehen soll. Insbesondere durch die Graubereiche des Wahrheitsgehalts
                ist das Löschen aller potenzieller Desinformationen oder das binäre Markieren als „wahr“ oder „falsch“ ohne
                Erklärungen kritisch zu betrachten, da es zum Abwandern zu weniger beaufsichtigten Plattformen und zu
                generellen Widerstandsreaktionen führt.
    
                Wie gelingt eine Adressierung von Graubereichen? Studien zeigen, dass Nutzende ein gewisses Maß an
                Transparenz und Verständlichkeit präferieren. Erste Hilfestellungen in der Mensch-Computer-Interaktion
                adressieren diese Anforderung. Typisch ist hier zum Beispiel die Anzeige von Indikatoren. Indikatoren sind
                verständliche Merkmale von Desinformation oder Fehlinformation (z. B. Anspruch auf absolute Wahrheit,
                emotionalisierende Hintergrundmusik), die bei der Einschätzung des Wahrheitsgehalts helfen können.
    
                Durch das Einblenden von Indikatoren auf vorgefilterter Desinformation soll ein Lerneffekt erzielt werden,
                etwa indem gezeigt wird, wie alt ein Video tatsächlich ist. Studien in diesem Kontext entwickeln Hinweise zu
                Indikatoren von Desinformation in Text, Audio und Video.
    
                Indikatorbasierte Interventionen stellen im Vergleich zu reinen „wahr oder falsch“-Ansätzen eine weniger
                invasive Maßnahme dar, die bestehende Graubereiche im Wahrheitsgehalt adressieren und Chancen für die
                informierte Navigation von Informationen bieten.
    
                Desinformation im Kontext der U.S.-Wahlen hat deutlich aufgezeigt, wie relevant eine differenzierte
                Betrachtung von Informationen ist und welche Formen Graubereiche des Wahrheitsgehalts annehmen können. Auch
                auf den deutschen (politischen) Kontext sind Erkenntnisse zu Interventionen übertragbar, welche in Form von
                Indikatoren einen informierten Umgang mit Informationen unterstützen. Dies steht Ansätzen entgegen, welche
                Inhalte ohne weitere Erklärungen als „falsch“ oder „wahr“ klassifizieren.
    
                Für anstehende Bundestagswahlen in Deutschland ist eine Betrachtung der Bedürfnisse von Bürgerinnen und
                Bürger von zentraler Bedeutung.
    
                Einblicke in Wahrnehmungen der deutschen Bevölkerung wurden bereits in Studien untersucht: Dies umfasst die
                Wahrnehmung polarisierender Themen wie Einwanderung, Gesundheit, Krieg in der Ukraine, Politik und Wahlen
                sowie Klimawandel als besonders relevant im Kontext von Desinformation. Weiter zeigt die Studienlage auch in
                Deutschland eine besondere Relevanz multimodaler Plattformen wie TikTok.
    
                Die nutzerzentrierte Entwicklung von Interventionen kann einen Beitrag zur Unterstützung im Umgang mit
                Desinformation leisten und ist als Ergänzung zu bestehenden Maßnahmen wie Medienkompetenzbildung in Schulen
                und darüber hinaus zu sehen. Dabei ist es zentral, die Bedürfnisse von Nutzerinnen und Nutzern (z. B.
                bezüglich Verständlichkeit) und plattformspezifische Irreführungspotenziale (z.B. bezüglich Kurzvideos auf
                TikTok) zu adressieren.
    
                Dieser Artikel ist in ähnlicher Fassung bei Table-Briefings erschienen. Beigesteuert wurde er von Dr.-Ing.
                Katrin Hartwig und Prof. Dr. Dr. Christian Reuter. Beide forschen an der Technischen Universität Darmstadt
                am Bereich Wissenschaft und Technik für Frieden und Sicherheit (PEASEC). Der Text erschien zuerst in unserem
                Newsletter GI-Radar. Alle Ausgaben gibt es hier zum Nachlesen.
            </p>
            
        </article>

        <a href="../blogs.html" class="back-to-overview">Zurück zur Übersicht</a>
    </main>

    <footer class="footer">
        <hr>
        author: Juan
        <br>
        &copy; Copy Rights reserved
        <br>

    </footer>

</body>

</html>